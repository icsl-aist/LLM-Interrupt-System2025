"""
    task_generate.py
    ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¿ã‚¹ã‚¯ã€ã€ã€Œãƒ­ã‚°ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€ã«åŸºã¥ã„ã¦ã€
    ChatGPT APIã‚’ä½¿ç”¨ã—ã¦è¡Œå‹•è¨ˆç”»ã‚’ç”Ÿæˆã—ã€ä¿å­˜ã™ã‚‹
"""
import os
import json
import config

from .LLM_manager import ( 
    read_file, read_json, get_chat_response, 
    save_response_to_file,
    append_to_script_log,
    append_token_usage_log
)

def main(user_msg):
    print(f"ğŸ¤– [Task Generate] è¡Œå‹•è¨ˆç”»ã®ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™...")

    # ===== 1. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª­ã¿è¾¼ã¿ =====
    prompt_path = config.PROMPTS["task"]
    ext = os.path.splitext(prompt_path)[1].lower()
    
    try:
        if ext == '.json':
            create_task_prompt = read_json(prompt_path)
            system_prompt_str = json.dumps(create_task_prompt, indent=2, ensure_ascii=False)
        else:
            system_prompt_str = read_file(prompt_path)
    except FileNotFoundError:
        print(f"âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {prompt_path}")
        return

    # ===== 2. ãƒ­ã‚°ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ =====
    log_path = config.LOGS["task"]
    log_content = "" 
    # if os.path.exists(log_path):
    #     log_content = read_file(log_path)
    
    # ===== 3. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµåˆ =====
    combined_prompt = (
        f"{system_prompt_str}\n\n"
        f"### User Task ###\n{user_msg}\n\n"
        f"### Log Content ###\n{log_content}"
    )
    
    # ===== 4. ãƒ¬ã‚¹ãƒãƒ³ã‚¹å–å¾— =====
    # (res=ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸, usage=ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±)
    res, usage = get_chat_response(combined_prompt)

    # ===== 5. ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä¿å­˜ =====
    output_path = config.LLM_TASK_SCRIPT_PATH
    save_response_to_file(res, output_path)

    # ===== 6. ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«è¿½è¨˜ =====
    append_to_script_log(output_path, log_path)

    # ===== 7. ãƒˆãƒ¼ã‚¯ãƒ³ãƒ­ã‚°è¨˜éŒ² =====
    append_token_usage_log(usage, config.LOGS["token"])
    
    print(f"âœ… ç”Ÿæˆã•ã‚ŒãŸã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")